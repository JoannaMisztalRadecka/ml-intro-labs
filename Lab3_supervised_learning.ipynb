{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3 - supervised-learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "w4wp_tyLIBGY"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aCxYatQKxKR"
      },
      "source": [
        "# Supervised learning with decision trees\n",
        "\n",
        "In supervised learning, a model is trained to predict the output value (target) based on the available features.\n",
        "\n",
        "In this notebook, we will learn how to use the decision tree model for supervised learning tasks (regression and classification problems).\n",
        "\n",
        "First, to get an intuition how it works, go through  the visual ML tutorial:\n",
        "\n",
        "*   http://www.r2d3.us/visual-intro-to-machine-learning-part-1/\n",
        "*   http://www.r2d3.us/visual-intro-to-machine-learning-part-2/\n",
        "\n",
        "\n",
        "We will use the same libs as in the previous lab (pandas and seaborn) and scikit-learn for training a machine learning model: https://scikit-learn.org/stable/tutorial/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4wp_tyLIBGY"
      },
      "source": [
        "#### Imports and functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSgp9ktcJR9w"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from IPython.display import Image \n",
        "import pydotplus\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, \\\n",
        "    GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics \n",
        "from sklearn.datasets import load_boston, load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.externals.six import StringIO  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY61OzwEQfGc"
      },
      "source": [
        "def plot_decision_tree(model, feature_names):\n",
        "  dot_data = StringIO()\n",
        "  export_graphviz(model, out_file=dot_data,  \n",
        "                  filled=True, rounded=True, \n",
        "                  feature_names=feature_names)\n",
        "  graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "  return Image(graph.create_png())\n",
        "\n",
        "def display_confusion_matrix(y_test, y_pred):\n",
        "  confusion_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, y_pred))\n",
        "  confusion_matrix.index.name = 'Actual'\n",
        "  confusion_matrix.columns.name = 'Predicted'\n",
        "  sns.heatmap(confusion_matrix, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uei_NZxyQcoZ"
      },
      "source": [
        "# Regression model\n",
        "First, we will apply the tree models to a regression problem - we will predict the price of houses in Boston area."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2NAS2ttMrRP"
      },
      "source": [
        "## Dataset exploration\n",
        "We will train the model on a built-in scikit-learn dataset of house prices in Boston.\n",
        "https://scikit-learn.org/stable/datasets/toy_dataset.html#boston-house-prices-dataset\n",
        "\n",
        "First, we load and explore the characteristics of the dataset (use the same methods as in the previous lab)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Egb6_v3JjaK"
      },
      "source": [
        "house_price_data = load_boston()\n",
        "house_price_data_pd = pd.DataFrame(house_price_data.data, columns=house_price_data.feature_names)\n",
        "house_price_data_pd.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dU8j6dMnoC8"
      },
      "source": [
        "Calculate the dataset statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvUlqgrtLxE4"
      },
      "source": [
        "house_price_data_pd.??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkUrPByBnvHm"
      },
      "source": [
        "We will predict the price of the houses in Boston based on their metadata. \n",
        "\n",
        "Plot the distribution of price value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3fVj2DKLrZB"
      },
      "source": [
        "sns.??(house_price_data.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToF6OMNYntEJ"
      },
      "source": [
        "Plot the feature correlation matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWWxBA3eKd1c"
      },
      "source": [
        "??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQyN4wyFNrZ7"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-lJ8GRYn9_1"
      },
      "source": [
        "To know if our model can generalize on unseen data, we are going to split the dataset into training and test data (20% examples). The model will be trained on the train split and the evaluation metrics will be calculated on test data.\n",
        "\n",
        " We use `train_test_split` from scikit-learn: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGM6XqqlMs17"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(house_price_data_pd, house_price_data.target, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kkkiv5jOCs2"
      },
      "source": [
        "We will use a decision tree regression model: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
        "\n",
        "First, we create the model and next, we train it on the train data (with `.fit()` method)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OalltKnNE7a"
      },
      "source": [
        "model = DecisionTreeRegressor()\n",
        "model = model.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r532xVUFOUiv"
      },
      "source": [
        "We can visualize the tree structure with a graph.  What can you say from this plot? Is it easy to interpret?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s_rqFngxNkwA"
      },
      "source": [
        "plot_decision_tree(model, house_price_data.feature_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p78SrtWOOo71"
      },
      "source": [
        "First, to verify if the model learned the training data, we will calculate the mean absolute error between the real and predicted value on the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z-hFho3OJGO"
      },
      "source": [
        "y_pred = model.predict(X_train)\n",
        "metrics.mean_absolute_error(y_train, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA0UyjFDPAKH"
      },
      "source": [
        "Next, to check how it generalizes on new examples, calculate the error on the test set (use `X_test` and `y_test` variables):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VTKi_XyNYpy"
      },
      "source": [
        "??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaT_Wh5jPEoQ"
      },
      "source": [
        "Why are these values different? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK4lGYT-Qi8n"
      },
      "source": [
        "### Tuning the model hyper-parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HJgIswiPb8E"
      },
      "source": [
        "If the difference between the error on the train and test sets is high, it means that the model **overfits** on the training set (it just learn the train examples by heart). \n",
        "\n",
        "Now, try to restrict the model by limiting the `max_depth` parameter to 3 and `min_samples_leaf` to 10. Plot the structure and analyze the errors. What can you say about the tree structure and errors for the train and test sets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Una-r90CNrNb"
      },
      "source": [
        "model = DecisionTreeRegressor(max_depth=3, min_samples_leaf=10)\n",
        "model = model.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atOM7T57PLV9"
      },
      "source": [
        "plot_decision_tree(model, house_price_data.feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QqVJ1pu5gfo"
      },
      "source": [
        "Calculate the predictions and error on the train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBQ6qWNVPbTv"
      },
      "source": [
        "??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci7b4Ydf5m7r"
      },
      "source": [
        "Calculate the predictions and error on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQhTrxf-PNDf"
      },
      "source": [
        "??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMsDPRfTQXj6"
      },
      "source": [
        "Try some other values of max depth and min samples. Can you improve the results on the test set?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdqPn6OZQ1dF"
      },
      "source": [
        "### Grid search and cross-validation\n",
        "\n",
        "We could improve the results by manually selecting the hyperparameters. However, if there are many parameters to tune, this approach will take a very long time. \n",
        "\n",
        "Now, we will select these values automatically. We will use grid search to compare the results for all combinations of hyperparameters and cross-validation to iteratively split the training and validation sets (to avoid overfitting to a single test set).\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sfde9JlPdoH"
      },
      "source": [
        "param_grid = {'max_depth': [2, 3, 5, 10], 'min_samples_leaf': [1, 5, 10]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klSYPTJkQCpH"
      },
      "source": [
        "model = DecisionTreeRegressor()\n",
        "search = GridSearchCV(model, param_grid)\n",
        "search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEBL5SQMQ8FR"
      },
      "source": [
        "plot_decision_tree(search.best_estimator_, house_price_data.feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrzW0ktCU8uY"
      },
      "source": [
        "What are the best parameters and the test error for this configuration of the model? Is it better than for the manually selected values?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9C7MtwHQlfu"
      },
      "source": [
        "print(search.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rm7I-YEQvxI"
      },
      "source": [
        "y_pred = search.predict(y_test)\n",
        "?? # print the error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5zdIJgSVNY9"
      },
      "source": [
        "## Model ensemble \n",
        "\n",
        "Next, we will try to improve the results and reduce overfitting by using an ensemble of models.\n",
        "\n",
        "### Random forest\n",
        "We will train a random forest model and tune its parameters with grid search and cross validation. This model is an ensemble of single decision trees - it fits a tree model to different subsamples of the dataset. Next, the results of particular estimators are averaged to get the final result. This method is more robust to overfitting than a single estimator.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJCupgRzRPh6"
      },
      "source": [
        "param_grid = {'max_depth': [2, 3, 5, 10], 'min_samples_leaf': [1, 5, 10], 'n_estimators': [50, 100, 200]}\n",
        "model = RandomForestRegressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugDXekBh6KCe"
      },
      "source": [
        "Run grid search on the random forest model and parameter grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmYBpjoW6IEz"
      },
      "source": [
        "??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op0URY1pWoKt"
      },
      "source": [
        "What are the best parameters for this model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XKPhDgPSpTD"
      },
      "source": [
        "??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l31dL5HWqvU"
      },
      "source": [
        "Calculate the error on the test set for this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_5H62ajSuzm"
      },
      "source": [
        "??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzgn1kZuQjf-"
      },
      "source": [
        "# Classification model\n",
        "Next, we will train a model on a binary classification task. We will predict if the patient has breast cancer based on the information from a medical image.\n",
        "Dataset description: \n",
        "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UctWP_dkZuey"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PklN26N1QlSj"
      },
      "source": [
        "breast_cancer_dataset = load_breast_cancer()\n",
        "breast_cancer_dataset_pd = pd.DataFrame(breast_cancer_dataset.data, columns=breast_cancer_dataset.feature_names)\n",
        "breast_cancer_dataset_pd.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn1p6R0CRXv1"
      },
      "source": [
        "breast_cancer_dataset_pd.describe() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFmn0rLRxiD3"
      },
      "source": [
        "Use seaborn `countplot` to plot the number of examples in each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pwSJKO4RiEf"
      },
      "source": [
        "??(breast_cancer_dataset.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH7vetr3Zzda"
      },
      "source": [
        "### Prepare data for training \n",
        "Create train and test splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1eAHTUFRt_N"
      },
      "source": [
        "X_train, X_test, y_train, y_test = ??(breast_cancer_dataset_pd, breast_cancer_dataset.target, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yj00XokZ8P5"
      },
      "source": [
        "### Train a decision tree classifier\n",
        "Plot the structure and print the best parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whcjtKI3W5KF"
      },
      "source": [
        "param_grid = {'max_depth': [2, 3, 5, 10], 'min_samples_leaf': [1, 5, 10]}\n",
        "model = DecisionTreeClassifier()\n",
        "search = GridSearchCV(model, param_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRmGYP1E8Z5Q"
      },
      "source": [
        "Fit the grid search model, print the best hyperparameters and plot the decision tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh3BtpcM8iq0"
      },
      "source": [
        "??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bokPT5jSaPTR"
      },
      "source": [
        "#### Calculate the evaluation metrics\n",
        "\n",
        "Print the classification accuracy (percentage of correctly predicted classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqL2VlSlYMPO"
      },
      "source": [
        "y_pred = search.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmh5zlDxabcB"
      },
      "source": [
        "The accuracy is useful but it does not show the complete information about the classification results (in particular, for unbalanced classes).\n",
        "\n",
        "We can display the confusion matrix to visualize the number of correctly (True Positive/True Negative) and incorrectly (False Positive/False Negative) classified instances for each class  ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVvduRXxYPH5"
      },
      "source": [
        "display_confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h7J5cIbauQ8"
      },
      "source": [
        "### Train a random forest \n",
        "Use grid search, print best hyperparams and perform the same evaluation as for the decision tree classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZbB1qwwR9-f"
      },
      "source": [
        "param_grid = {'max_depth': [2, 3, 5, 10], 'min_samples_leaf': [1, 5, 10],\n",
        "              'n_estimators': [50, 100, 200]}\n",
        "model = RandomForestClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRJWv1PM88JR"
      },
      "source": [
        "Fit grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJyiLpLiSmEI"
      },
      "source": [
        "??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsvAHCsi8-uH"
      },
      "source": [
        "Print best params and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIowy7k-VnSt"
      },
      "source": [
        "??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1p9uWPZ9BNf"
      },
      "source": [
        "Display the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsL-vqdsVgXz"
      },
      "source": [
        "??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRphwVb9V3Nq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3y4LKj5XomJ"
      },
      "source": [
        "# What to remember\n",
        "\n",
        "* In supervised learning, we train a model to learn the output (target) based on the input (features).\n",
        "* In regression problems, the model predicts a continuous value (eg. house prices). In classification, the model predicts a category (eg. sickness or not).\n",
        "* To evaluate the model, we split the dataset to train and test sets. The model is trained on training data, and the metrics are calculated on test data.\n",
        "* If the difference between train and test metrics is high, the model *overfits*. We can reduce the overfitting by adding some restriction to the model parameters.\n",
        "* A decision tree is a useful model which is easy to interpret. A random forest is an ensemble of decision trees. Usually, it has a better accuracy but it is more difficult to interpret."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV3BIe_gYhcD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}